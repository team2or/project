import tensorflow
import keras
from keras.models import load_model
# from tensorflow.keras.preprocessing.text import Tokenizer #토큰화
from tensorflow.keras.preprocessing.sequence import pad_sequences #패딩
import eunjeon
import pickle5 as pickle

#model=load_model('E:\git\ecademy\flask_test\best_model.h5')
class Predict:
    def __init__(self):
        self.model=load_model('model.h5')
        self.mecab=eunjeon.Mecab()
        # loading
        with open('tokenizer.pickle', 'rb') as handle:
            self.tokenizer = pickle.load(handle)
        self.stopwords=['을','는','이가','께서','것','의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','문의','전화','주문','예약','프로필','카톡','하단','링크','클릭','채널','댓글','및','아녹플라워','물량이2월의','이벤트안녕하세요']
    def predict_(self,sentence):
        new_token=[word for word in self.mecab.morphs(sentence) if word not in self.stopwords]
        new_sequences= self.tokenizer.texts_to_sequences([new_token])
        new_pad= pad_sequences(new_sequences, maxlen=2500)
        score=(self.model.predict(new_pad))
        label=['술집','카페','음식','전시','꽃집','미용실','연극']
        results = {'score':'', 'result':''}
        for i in score:
            j=[round(x*100,2) for x in i]
            results['score'] = '\n'.join(list(map(str,j)))
            for i in j:
                if i >20:
                    results['result'] += f'{label[j.index(i)]} {i}%<br>'
        if results['result'] == '\n카페 20.71%\n음식 54.61%\n':
            results['result'] = '결과없음<br>'
            results['score'] = '0\n0\n0\n0\n0\n0\n0'
        return results